{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8459af",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c93566",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mglearn\n",
    "\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'New Gulim'\n",
    "rcParams['font.size'] = 10\n",
    "rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1181809",
   "metadata": {},
   "source": [
    "# 1 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a78030",
   "metadata": {},
   "source": [
    "[선형 회귀](https://kimdingko-world.tistory.com/101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba15c66",
   "metadata": {},
   "source": [
    "모델 | 설명\n",
    ":--- |:---\n",
    "일반 선형 회귀 | 예측값과 측정값의 오차를 최소화할 수 있도록 회귀 계수를 최적화\n",
    "릿지(Ridge) | 선형 회귀에 L2 규제를 추가한 모델. L2 규제는 상대적으로 큰 회귀 계수값을 더 작게 만드는 규제 모델\n",
    "라쏘(Lasso) | 선형 회귀에 L1 규제를 추가한 모델. L1 규체즌 영향력이 작은 피처의 회귀 계수값을 0으로 만드는 규제 모델(피처 선택 기능)\n",
    "엘라스틱넷(ElasticNet) | L2 규제와 L1 규제를 결합한 모델. 주로 피처가 많은 데이터 셋에 적용\n",
    "로지스틱 회귀(Logistic Regression) | 분류에 사용되는 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee08168",
   "metadata": {},
   "source": [
    "### 1.1 경사 하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56e0e2",
   "metadata": {},
   "source": [
    "#### 1.1.1 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# y = 4X + 6 + noise(random)\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 6 + 4 * X + np.random.randn(100,1)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828556e1",
   "metadata": {},
   "source": [
    "#### 1.1.2 가중치 업데이트 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 업데이트 함수 정의\n",
    "def get_weight_updates(w1, w0, X, y, learning_rate=0.01):\n",
    "    N = len(y)\n",
    "    \n",
    "    # w1_update, w0_update 0으로 초기화\n",
    "    w1_update = np.zeros_like(w1)\n",
    "    w0_update = np.zeros_like(w0)\n",
    "    \n",
    "    # 예측값 계산 & 오차 계산(실제값 - 예측값)\n",
    "    y_pred = np.dot(X, w1.T) + w0\n",
    "    diff = y-y_pred\n",
    "         \n",
    "    # w0_update를 dot 행렬 연산으로 구하기 위해 모두 1값을 가진 행렬 생성 \n",
    "    w0_factors = np.ones((N,1))\n",
    "\n",
    "    # w1과 w0을 업데이트할 w1_update와 w0_update 계산\n",
    "    w1_update = -(2/N)*learning_rate*(np.dot(X.T, diff))\n",
    "    w0_update = -(2/N)*learning_rate*(np.dot(w0_factors.T, diff))    \n",
    "    \n",
    "    return w1_update, w0_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29bbd3",
   "metadata": {},
   "source": [
    "#### 1.1.3 경사하강법 적용 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6145322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1, w0 업데이트: iters 만큼 반복 적용\n",
    "def gradient_descent_steps(X, y, iters=10000):\n",
    "    # w0, w1초기화\n",
    "    w0 = np.zeros((1,1))\n",
    "    w1 = np.zeros((1,1))\n",
    "    \n",
    "    # w1, w0 업데이트: iters 만큼 반복 적용\n",
    "    for ind in range(iters):\n",
    "        w1_update, w0_update = get_weight_updates(w1, w0, X, y, learning_rate=0.01)\n",
    "        w1 = w1 - w1_update\n",
    "        w0 = w0 - w0_update\n",
    "              \n",
    "    return w1, w0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a573621",
   "metadata": {},
   "source": [
    "#### 1.1.4 비용 구하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(y, y_pred):\n",
    "    N = len(y) \n",
    "    cost = np.sum(np.square(y - y_pred))/N\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdedee2d",
   "metadata": {},
   "source": [
    "#### 1.1.5 경사하강법 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a5221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 4X + 6\n",
    "\n",
    "w1, w0 = gradient_descent_steps(X, y, iters=1000)\n",
    "print('w1:{:.3f} w0:{:.3f}'.format(w1[0,0], w0[0,0]))\n",
    "\n",
    "y_pred = w1[0,0] * X + w0\n",
    "print('Gradient Descent Total Cost:{:.4f}'.format(get_cost(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ad552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X,y_pred)\n",
    "plt.title('경사하강법 적용')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eed9d7",
   "metadata": {},
   "source": [
    "#### 1.1.6 확률적 경사하강법(SGD) 적용 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc632c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_steps(X, y, batch_size=10, iters=1000):\n",
    "    # w0, w1초기화\n",
    "    w0 = np.zeros((1,1))\n",
    "    w1 = np.zeros((1,1))\n",
    "    \n",
    "    for ind in range(iters):\n",
    "        np.random.seed(ind)\n",
    "        # sample_X, sample_y: batch_size만큼 랜덤 데이터 추출\n",
    "        stochastic_random_index = np.random.permutation(X.shape[0])\n",
    "        sample_X = X[stochastic_random_index[0:batch_size]]\n",
    "        sample_y = y[stochastic_random_index[0:batch_size]]\n",
    "        \n",
    "        # w1, w0 업데이트: 추출된 부분 데이터 사용(sample_X, sample_y)\n",
    "        w1_update, w0_update = get_weight_updates(w1, w0, sample_X, sample_y, learning_rate=0.01)\n",
    "        w1 = w1 - w1_update\n",
    "        w0 = w0 - w0_update\n",
    "    \n",
    "    return w1, w0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee07bb",
   "metadata": {},
   "source": [
    "#### 1.1.7 확률적 경사하강법(SGD) 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1face",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 4X + 6\n",
    "\n",
    "w1, w0 = stochastic_gradient_descent_steps(X, y, iters=1000)\n",
    "print('w1:{:.3f} w0:{:.3f}'.format(w1[0,0], w0[0,0]))\n",
    "\n",
    "y_pred = w1[0,0] * X + w0\n",
    "print('Stochastic Gradient Descent Total Cost:{:.4f}'.format(get_cost(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X,y_pred)\n",
    "plt.title('확률적 경사하강법(SGD) 적용')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617eeef8",
   "metadata": {},
   "source": [
    "### 1.2 선형 회귀 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18877e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "df = pd.read_csv('data/boston.csv')\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67837e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error , r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37849e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y, random_state=123)\n",
    "\n",
    "# Linear Regression: 학습\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train ,y_train )\n",
    "\n",
    "# Linear Regression: 예측, 평가\n",
    "pred = lr.predict(X_test)\n",
    "mse  = mean_squared_error(y_test, pred)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fe2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE:',  mse)\n",
    "print('RMSE:', rmse)\n",
    "print('R squared score:', r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d25f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 절편\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 계수\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 계수 정렬\n",
    "coeff = pd.Series(data=np.round(lr.coef_, 1), index=df.drop('target',axis=1).columns )\n",
    "coeff.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score 적용\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "neg_mse_scores = cross_val_score(lr, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "rmse_scores    = np.sqrt(-1 * neg_mse_scores)\n",
    "\n",
    "avg_rmse = np.mean(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 2))\n",
    "print('5 folds 의 개별 RMSE scores : ', np.round(rmse_scores, 2))\n",
    "print('5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e486b",
   "metadata": {},
   "source": [
    "# 2 Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea76be4",
   "metadata": {},
   "source": [
    "- 언더 피팅\n",
    "- 오버 피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d437ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda68d1",
   "metadata": {},
   "source": [
    "### 2.1 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ec4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "n_samples = 30\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "\n",
    "# Cosine + Noise\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58830ccc",
   "metadata": {},
   "source": [
    "### 2.2 다항 회귀 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db749982",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "degrees = [1, 4, 15]\n",
    "\n",
    "# 다항 회귀의 차수(degree)를 1, 4, 15로 각각 변화시키면서 비교합니다. \n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "    \n",
    "    # 개별 degree별로 Polynomial 변환합니다. \n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X.reshape(-1, 1), y)\n",
    "    \n",
    "    # 교차 검증으로 다항 회귀를 평가합니다. \n",
    "    scores = cross_val_score(pipeline, X.reshape(-1,1), y,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    coefficients = pipeline.named_steps['linear_regression'].coef_\n",
    "    print('\\nDegree {0} 회귀 계수는 {1} 입니다.'.format(degrees[i], np.round(coefficients),2))\n",
    "    print('Degree {0} MSE 는 {1:.2f} 입니다.'.format(degrees[i] , -1*np.mean(scores)))\n",
    "    \n",
    "    # 0 부터 1까지 테스트 데이터 세트를 100개로 나눠 예측을 수행합니다. \n",
    "    # 테스트 데이터 세트에 회귀 예측을 수행하고 예측 곡선과 실제 곡선을 그려서 비교합니다.  \n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    # 예측값 곡선\n",
    "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\") \n",
    "    # 실제 값 곡선\n",
    "    plt.plot(X_test, true_fun(X_test), '--', label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    \n",
    "    plt.xlabel(\"x\"); plt.ylabel(\"y\"); plt.xlim((0, 1)); plt.ylim((-2, 2)); plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(degrees[i], -scores.mean(), scores.std()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27bbe2",
   "metadata": {},
   "source": [
    "# 3 Regularized Linear Models – Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb4696",
   "metadata": {},
   "source": [
    "### 3.1 Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "df = pd.read_csv('data/boston.csv')\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35200820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a939109",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 10)\n",
    "neg_mse_scores = cross_val_score(ridge, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226cb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 3))\n",
    "print('5 folds 의 개별 RMSE scores : ', np.round(rmse_scores,3))\n",
    "print('5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge에 사용될 alpha 파라미터의 값들을 정의\n",
    "alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "\n",
    "# alphas list 값을 iteration하면서 alpha에 따른 평균 rmse 구함.\n",
    "for alpha in alphas :\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    \n",
    "    #cross_val_score를 이용하여 5 fold의 평균 RMSE 계산\n",
    "    neg_mse_scores = cross_val_score(ridge, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {} 일 때 5 folds 의 평균 RMSE: {:.3f}'.format(alpha, avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce53826",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , axs = plt.subplots(figsize=(18,6) , nrows=1 , ncols=5)\n",
    "coeff_df = pd.DataFrame()\n",
    "\n",
    "# alphas 리스트 값을 차례로 입력해 회귀 계수 값 시각화 및 데이터 저장. pos는 axis의 위치 지정\n",
    "for pos , alpha in enumerate(alphas) :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X, y)\n",
    "    \n",
    "    # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가.  \n",
    "    coeff = pd.Series(data=ridge.coef_ , index=df.drop('target',axis=1).columns )\n",
    "    colname='alpha:'+ str(alpha)\n",
    "    coeff_df[colname] = coeff\n",
    "    \n",
    "    # 막대 그래프로 각 alpha 값에서의 회귀 계수를 시각화. 회귀 계수값이 높은 순으로 표현\n",
    "    coeff = coeff.sort_values(ascending=False)\n",
    "    axs[pos].set_title(colname)\n",
    "    axs[pos].set_xlim(-3,6)\n",
    "    sns.barplot(x=coeff.values , y=coeff.index, ax=axs[pos])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "sort_column = 'alpha:'+ str(ridge_alphas[0])\n",
    "coeff_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5645b1",
   "metadata": {},
   "source": [
    "### 3.2 Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238cf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fc2080",
   "metadata": {},
   "source": [
    "#### Ridge, Lasso, ElasticNet 모델 적용 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고 회귀 계수값들을 DataFrame으로 반환\n",
    "\n",
    "def get_linear_reg_eval(model_name, params=None, X_n=None, y_n=None ):\n",
    "    coeff_df = pd.DataFrame()\n",
    "    \n",
    "    print('####### ', model_name , '#######')\n",
    "    \n",
    "    for param in params:\n",
    "        if   model_name =='Ridge': model = Ridge(alpha=param)\n",
    "        elif model_name =='Lasso': model = Lasso(alpha=param)\n",
    "        elif model_name =='ElasticNet': model = ElasticNet(alpha=param, l1_ratio=0.7)\n",
    "        \n",
    "        neg_mse_scores = cross_val_score(model, X_n, y_n, scoring='neg_mean_squared_error', cv=5)\n",
    "        avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "        print('alpha {}일 때 5 폴드 세트의 평균 RMSE: {:.3f}'.format(param, avg_rmse))\n",
    "        \n",
    "        # cross_val_score는 evaluation metric만 반환하므로 모델을 다시 학습하여 회귀 계수 추출\n",
    "        model.fit(X_n , y_n)\n",
    "        # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가. \n",
    "        coeff = pd.Series(data=model.coef_ , index=df.drop('target',axis=1).columns )\n",
    "        colname='alpha:'+ str(param)\n",
    "        coeff_df[colname] = coeff\n",
    "        \n",
    "    return coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396fc578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라쏘에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "lasso_alphas = [0.07, 0.1, 0.5, 1, 3]\n",
    "\n",
    "coeff_lasso_df = get_linear_reg_eval('Lasso', params=lasso_alphas, X_n=X, y_n=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45923288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환된 coeff_lasso_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+ str(lasso_alphas[0])\n",
    "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e947040",
   "metadata": {},
   "source": [
    "### 3.3 ElasticNet regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb07134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엘라스틱넷에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "# l1_ratio는 0.7로 고정\n",
    "elastic_alphas = [0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_elastic_df = get_linear_reg_eval('ElasticNet', params=elastic_alphas, X_n=X, y_n=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a84dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환된 coeff_elastic_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+ str(elastic_alphas[0])\n",
    "coeff_elastic_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e456f",
   "metadata": {},
   "source": [
    "# 4 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fc930",
   "metadata": {},
   "source": [
    "- Sigmoid function\n",
    "- Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac503c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00187ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb5dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train , X_test, y_train , y_test = train_test_split(data_scaled, cancer.target, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀: 학습, 예측\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 로지스틱 회귀를 이용하여 학습 및 예측 수행. \n",
    "lr_clf = LogisticRegression(C=1)\n",
    "#lr_clf = LogisticRegression(C=0.01)\n",
    "#lr_clf = LogisticRegression(C=10)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "\n",
    "# accuracy와 roc_auc 측정\n",
    "print('accuracy: {:0.3f}'.format(accuracy_score(y_test, lr_preds)))\n",
    "print('roc_auc: {:0.3f}'.format(roc_auc_score(y_test , lr_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076fa13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855586d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": true,
   "vp_note_width": 263,
   "vp_position": {
    "width": 541
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
